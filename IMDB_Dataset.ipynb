{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of Large Movie Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rania\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: thinc.extra.search.Beam size changed, may indicate binary incompatibility. Expected 112 from C header, got 120 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#for preprocessing:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like the distribution of positive and negative examples are almost equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e01f68a8c8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"IMDB Dataset.csv\",header=None)\n",
    "data = data1.iloc[1:1000,0]\n",
    "#plotting the graph about target variable\n",
    "data1.iloc[1:1000,1].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding length and punctuation to see if thers any correlation with target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "punctuation = ['.',',','?','!',';',':','-','_','{}','[]','()','\\'','\\\"\"','...',\"''\"]\n",
    "review=[]\n",
    "length=[]\n",
    "punc_count=[]\n",
    "for i in range(1,len(data)+1):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", data[i].lower()) ]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \",data[i].lower())] \n",
    "    review.append(reviews)\n",
    "    for j in range(len(reviews)):\n",
    "        length.append(len(reviews[j]))\n",
    "    doc = nlp(str(reviews)) \n",
    "    k=0\n",
    "    for token in doc:\n",
    "        if (token.text in punctuation):\n",
    "            k=k+1\n",
    "    punc_count.append(k)\n",
    "print(len(length))\n",
    "print(len(punc_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rearranging data and adding updated review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data1.rename({0: \"review\", 1: \"sentiment\"},axis='columns')\n",
    "df = df.drop(columns=['review'])\n",
    "df = df.iloc[1:1000,:]\n",
    "#data1=data1.rename({0: \"review\", 1: \"sentiment\", 2: \"punctuation\", 3:\"length\"},axis='columns')\n",
    "#data1 = data1.drop(['review'],axis=1)\n",
    "df.loc[1:1000,2] = punc_count\n",
    "df.loc[1:1000,3] = length\n",
    "df.loc[1:1000,4] = review\n",
    "df=df.rename({ 2: \"punctuation\", 3:\"length\",4:\"review\"},axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df.iloc[:,0]=='positive'].iloc[:,2],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df.iloc[:,0]=='negative'].iloc[:,2],bins=bins,alpha=0.8)\n",
    "plt.legend(('positive','negative'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Negative reviews kind of appear to be longer which does make sense!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df.iloc[:,0]=='positive'].iloc[:,1],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df.iloc[:,0]=='negative'].iloc[:,1],bins=bins,alpha=0.8)\n",
    "plt.legend(('positive','negative'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuations dont give out any difference! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X is our feature data\n",
    "X=df[['punctuation','length']] \n",
    "y = df['sentiment']\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print('Training Data Shape:', X_train.shape)\n",
    "print('Testing Data Shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Create a prediction set:\n",
    "predictions = lr_model.predict(X_test)\n",
    "df_output = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['positive','negative'], columns=['positive','negative'])\n",
    "df_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Logistic regression isn't doing well with the predictions(equally falsely predicted with correctly predicted)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The classifier works good only for negative class !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(gamma='auto')\n",
    "svc_model.fit(X_train,y_train)\n",
    "predictions = svc_model.predict(X_test)\n",
    "df_output = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['positive','negative'], columns=['positive','negative'])\n",
    "df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Till now we have used only length and punctuation to predict! Since it isnt working weel lets use Text extraction feature to get some meaning from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['review']\n",
    "y = df['sentiment']\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that Text extraction feature is useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "df_output1 = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['positive','negative'], columns=['positive','negative'])\n",
    "print(df_output1)\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'This was a good movie.'\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comp_score'] = df['compound'].apply(lambda c: 'positive' if c >=0 else 'negative')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy isnt impressive as it was in TF-IDFVector which makes sense we didnt actually train any data and Vader cant depict Sarcasm!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(df['sentiment'],df['comp_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(df['sentiment'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(df['sentiment'],df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
